{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificaci√≥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest tercer lliurament es programar√† un classificador, que donat un tweet el categoritzar√† en una de les possibles classes. En aquesta ocasi√≥, implementareu un classificador amb tweets de pol√≠tics.\n",
    "\n",
    "\n",
    "**Qu√® s‚Äôha de fer?**\n",
    "\n",
    "Volem classificar tweets corresponents a diferents pol√≠tics segons a quin partit pol√≠tic pertanyen. \n",
    "A partir de tots els tweets que tenim, crearem un vector de caracter√≠stiques que ens descrigui cada un dels tweets. \n",
    "Finalment desenvoluparem un classificador probabil√≠stic del tipus Naive Bayes que ens permeti identificar a quin partit pol√≠tic pertany un tweet donat segons les caracter√≠stiques triades.\n",
    "\n",
    "\n",
    "**Quina √©s la idea del sistema de classificaci√≥ que s‚Äôha de desenvolupar?**\n",
    "\n",
    "El classificador √©s un concepte de l'aprenentatge autom√†tic supervisat. \n",
    "L'objectiu del classificador √©s donat un vector de caracter√≠stiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "El proc√©s de classificaci√≥ consta de dues parts: \n",
    "(a) el proc√©s d'aprenentatge i \n",
    "(b) el proc√©s d'explotaci√≥ o testeig. \n",
    "El proc√©s d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ s√≥n les caracter√≠stiques, usualment nombres reals, i $y$ √©s la categoria a la qual pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servir√† per trobar una funci√≥ $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el proc√©s de testeig aplica la funci√≥ $h(x)$ apresa a l'entrenament a una nova descripci√≥ per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificaci√≥ i llenguatge natural**\n",
    "\n",
    "La descripci√≥ dels exemples en caracter√≠stiques √©s el punt m√©s cr√≠tic de tot sistema d'aprenentatge autom√†tic. \n",
    "Una de les representacions m√©s simples per tal de descriure un text √©s la representaci√≥ *bag-of-words*.\n",
    "Aquesta representaci√≥ converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versi√≥ alternativa d'aquest proc√©s pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de comen√ßar\n",
    "\n",
    "\n",
    "**\\+ Durant la pr√†ctica, solament es podran fer servir les seg√ºents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A m√©s de les que ja es troben presents en la 1a cel¬∑la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i par√†metres ja donats**\n",
    "\n",
    "Aix√≤ no implica per√≤ que els h√†giu de fer servir. √âs a dir, que la funci√≥ tingui un par√†metre anomenat `df` no implica que l'h√†giu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica que ser√† i de quin tipus cada un dels par√†metres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posar√† en el pydoc de la funci√≥), `df` sempre ser√† indicatiu del `Pandas.DataFrame` de les dades. Durant els testos, els par√†metres (i espec√≠ficament `df`) no contindran les mateixes dades que en aquest notebook, si b√© si seran del mateix tipus! Per tant, no us refieu de qu√® tinguin, per exemple, el mateix nombre de files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testos autom√†tics\n",
    "\n",
    "Com ja sabeu, les pr√†ctiques es fan a trav√©s de Github Classroom. Podeu treballar-hi lliurement i es recomana que feu commits sovint, per tal que els canvis quedin reflectits de forma estructurada i modular.\n",
    "\n",
    "Normalment treballareu a la branca `master`, per√≤ podeu fer fins a 3 cops al dia un `commit` (o `merge` de `master`) a la branca `test`. Aix√≤ provocar√† que es llencin un seguit de proves sobre el vostre codi, en podreu veure el resultat a la seg√ºent web: http://grade-me.education\n",
    "\n",
    "Penseu que aquests testos s√≥n un subconjunt, petit, dels que realment farem servir per avaluar. Per tant, us recomanem que aprofiteu al m√†xim els 3 intents diaris, que us serviran per comprovar que els formats d'entrada i sortida siguin correctes, a m√©s d'alguns testos b√†sics de correcte funcionament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades\n",
    "\n",
    "### **En aquesta cel¬∑la no f√©u cap modificaci√≥**\n",
    "\n",
    "Descomprimeix el zip en la carpeta \"data\" autom√†ticament. La funci√≥ locate serveix per trobar la ruta relativa a la carpeta on s'est√† executant aquest python/ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join, dirname\n",
    "\n",
    "def locate(*path):\n",
    "    base = globals().get('__file__', '.')\n",
    "    return join(dirname(base), *path)\n",
    "\n",
    "try:\n",
    "    from IPython.core.display import HTML\n",
    "\n",
    "    def pprint(df):\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(HTML(pd.DataFrame(df).to_html()))\n",
    "except:\n",
    "    def pprint(df):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>√öltim acte de campanya! Aqu√≠ tossudament al√ßat...</td>\n",
       "      <td>2017-12-19 20:12:01</td>\n",
       "      <td>785</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xavierdomenechs</td>\n",
       "      <td>comuns</td>\n",
       "      <td>#Badalona necessita uns pressupostos que posin...</td>\n",
       "      <td>2018-04-27 10:04:19</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albert_rivera</td>\n",
       "      <td>cs</td>\n",
       "      <td>Encuentro Villac√≠s-Valls para lanzar una estra...</td>\n",
       "      <td>2018-11-17 20:34:58</td>\n",
       "      <td>357</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaumecollboni</td>\n",
       "      <td>psc</td>\n",
       "      <td>‚ÄúLa palabra es como una bala, no tiene retorno...</td>\n",
       "      <td>2018-10-22 18:10:01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albiol_xg</td>\n",
       "      <td>ppc</td>\n",
       "      <td>üìª Esta noche, a partir de las 22:10h, me entre...</td>\n",
       "      <td>2018-08-16 10:30:27</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avui hem repr√©s la Comissi√≥ Mixta amb el @gove...</td>\n",
       "      <td>67</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torra anunci√≥ un \"oto√±o caliente\" para aumenta...</td>\n",
       "      <td>856</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dem√† cal sortir als carrers per dir que #Barce...</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ÄúCerc√†vem or i vam baixar a la mina.\\nI la fos...</td>\n",
       "      <td>338</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Molt senzill d'entendre, companya: \\n1.- L'ALL...</td>\n",
       "      <td>4932</td>\n",
       "      <td>7253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 3)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Training data')\n",
    "    df_tweets_train = pd.read_excel(locate('data', 'train.xlsx'), index_col='Id')\n",
    "    pprint(df_tweets_train.head())\n",
    "    print(df_tweets_train.shape)\n",
    "    \n",
    "    df_tweets_test = pd.read_excel(locate('data', 'test.xlsx'), index_col='Id')\n",
    "    pprint(df_tweets_test.head())\n",
    "    print(df_tweets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementaci√≥\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. An√†lisis de dades: Informaci√≥ b√†sica sobre els tweets\n",
    "2. Processament de les dades: Creaci√≥ d'un vector de caracter√≠stiques a partir dels tweets\n",
    "3. Classificaci√≥ amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√†lisis de dades\n",
    "\n",
    "El primer que haurem de fer √©s analitzar les dades mitjan√ßant diferents funcions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(df):\n",
    "    \"\"\"\n",
    "    Retorna el n√∫mero de tweets en el dataframe\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : n√∫mero de tweets\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.shape[0]\n",
    "\n",
    "def get_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna els usuaris dels pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb el nom dels usuaris\n",
    "    \"\"\"\n",
    "    \n",
    "    return df['username'].unique()\n",
    "\n",
    "def count_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(get_politicians(df))\n",
    "\n",
    "def get_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna els partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Llista de strings amb el nom dels partits pol√≠tics que han tuitejat\n",
    "    \"\"\"  \n",
    "    \n",
    "    return df['party'].unique()\n",
    "\n",
    "def count_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de partits pol√≠tics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Enter amb la quantitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    return len(get_political_party(df))\n",
    "\n",
    "def count_tweet_politician(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Serie amb la quanitat de tweets per pol√≠tic\n",
    "    \"\"\"\n",
    "    return df.groupby(['username']).size()\n",
    "\n",
    "def count_tweet_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per partit pol√≠tic\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : pd.Serie amb la quantitat de tweets per partit pol√≠tic\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.groupby(['party']).size()\n",
    "\n",
    "def top_retweet(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets que han sigut m√©s retuitejats\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Serie amb els top retuits\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.sort_values(by=['retweet_count'],ascending=False)[:n]\n",
    "    \n",
    "def top_favorite(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets m√©s favorits\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params n: n√∫mero de tweets per veure\n",
    "    :return : pd.Serie amb els top favorits\n",
    "    \"\"\"\n",
    "    return df.sort_values(by=['favorite_count'],ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Correcte\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "1/1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "['martarovira' 'xavierdomenechs' 'albert_rivera' 'jaumecollboni'\n",
      " 'albiol_xg' 'miqueliceta' 'quimtorraipla' 'adacolau' 'santirodriguez'\n",
      " 'krls' 'joantarda' 'inesarrimadas'] 12\n",
      "['erc' 'comuns' 'cs' 'psc' 'ppc' 'jxcat'] 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>adacolau</td>\n",
       "      <td>comuns</td>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es b...</td>\n",
       "      <td>2018-10-26 22:17:38</td>\n",
       "      <td>11706</td>\n",
       "      <td>26838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tor...</td>\n",
       "      <td>2017-11-02 17:42:06</td>\n",
       "      <td>10403</td>\n",
       "      <td>19991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫te...</td>\n",
       "      <td>2018-08-29 20:21:30</td>\n",
       "      <td>10086</td>\n",
       "      <td>20357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>.@junqueras President d'un partit amb 86 anys ...</td>\n",
       "      <td>2017-12-13 21:17:18</td>\n",
       "      <td>9445</td>\n",
       "      <td>15947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Perdoneu, per√≤ aix√≤ √©s tan greu que si no hi h...</td>\n",
       "      <td>2018-09-19 20:16:22</td>\n",
       "      <td>8806</td>\n",
       "      <td>12509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>adacolau</td>\n",
       "      <td>comuns</td>\n",
       "      <td>Que una republicana defienda la Rep√∫blica es b...</td>\n",
       "      <td>2018-10-26 22:17:38</td>\n",
       "      <td>11706</td>\n",
       "      <td>26838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una causa que necessiti ser defensada amb c√∫te...</td>\n",
       "      <td>2018-08-29 20:21:30</td>\n",
       "      <td>10086</td>\n",
       "      <td>20357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Acabo d'arribar a #Esc√≤cia convidat pel F√≤rum ...</td>\n",
       "      <td>2018-08-24 17:55:01</td>\n",
       "      <td>6783</td>\n",
       "      <td>20018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>A tots els dem√≤crates: no pararem fins que tor...</td>\n",
       "      <td>2017-11-02 17:42:06</td>\n",
       "      <td>10403</td>\n",
       "      <td>19991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>krls</td>\n",
       "      <td>jxcat</td>\n",
       "      <td>Una gran #Diada2018 per avan√ßar cap a la rep√∫b...</td>\n",
       "      <td>2018-09-11 18:48:43</td>\n",
       "      <td>6372</td>\n",
       "      <td>18950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    print(count_tweets(df_tweets_train))\n",
    "    print(get_politicians(df_tweets_train), count_politicians(df_tweets_train))\n",
    "    print(get_political_party(df_tweets_train), count_political_party(df_tweets_train))\n",
    "    \n",
    "    count_tweet_politician(df_tweets_train).plot.bar()\n",
    "    plt.show()\n",
    "    \n",
    "    count_tweet_party(df_tweets_train).plot.bar()\n",
    "    plt.show()\n",
    "    \n",
    "    pprint(top_retweet(df_tweets_train, 5))\n",
    "    pprint(top_favorite(df_tweets_train, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar √©s la funci√≥ *normalize* que normalitzar√† les paraules.\n",
    "\n",
    "\n",
    "No modificar la seg√ºent cel¬∑la, s'encarrega d'evitar c√†lculs repetits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo    \n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funci√≥ que donada una paraula la normalitzi\n",
    "    Exemple: Taller DELS noUS USOS ---> tallers dels nous usos\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    \n",
    "    # Eliminar els accents\n",
    "    accents = {'√†':'a','√°':'a','√®':'e','√©':'e','√≠':'i','√≤':'o','√≥':'o','√∫':'u'}\n",
    "    for k,v in accents.items():\n",
    "        word = word.replace(k,v)\n",
    "    \n",
    "    # Eliminar els pronoms del catal√†\n",
    "    toRemove = [\"l'\",\"d'\",\"t'\",\"n'\",\"s'\",\"m'\",\"'m\",\"'t\",\"'s\",\"'l\",\"'ls\",\"'n\",\"'ns\"]\n",
    "    \n",
    "    for c in toRemove:\n",
    "        word = word.replace(c,'')\n",
    "    \n",
    "    # Utilitzar regular expressions i passar a minus\n",
    "    return re.sub(r'[^\\w\\s\\'\\@\\#\\-]','', word.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Correcte\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "1/1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un diccionari que contingui totes les paraules que s'han trobat indicant\n",
    "    el total de cops que ha aparegut i el nombre de tweets on apareix\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Diccionari amb el format {word : {n_ocur: valor, n_tweets: valor}, ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    dic = dict()\n",
    "    tweets = df['text']\n",
    "    # Per cada tweet\n",
    "    for tweet in tweets:\n",
    "        seen_words = set()\n",
    "        # Per cada paraula del tweet\n",
    "        for word in tweet.split():\n",
    "            norm_word = normalize(word) # normalitzar\n",
    "            current = dic.get(norm_word)\n",
    "            if not current:\n",
    "                # Si no est√† al diccionari inicialitzem\n",
    "                dicc_node = {'n_ocur':1, 'n_tweets':1}\n",
    "                dic[norm_word] = dicc_node\n",
    "            else: \n",
    "                # Actualitzar el diccionari\n",
    "                dic[norm_word]['n_ocur'] = dic[norm_word]['n_ocur'] + 1\n",
    "                if norm_word not in seen_words:\n",
    "                    # Si no hem vist aquesta paraula ja en el mateix tweet incrementem n_tweets\n",
    "                    dic[norm_word]['n_tweets'] = dic[norm_word]['n_tweets'] + 1\n",
    "                \n",
    "            seen_words.add(norm_word)\n",
    "            \n",
    "    return dic\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Correcte\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "3/3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11574\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dicc_text = count_words(df_tweets_train)\n",
    "    print(len(dicc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquest valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'badalona' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "    'que': {'n_ocur': 123, 'n_tweets': 65},\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per partit pol√≠tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_parties(df):\n",
    "    \"\"\"\n",
    "    Funci√≥ que ha de construir un diccionari que cont√© la freq√º√®ncia de les \n",
    "    paraules i el n√∫mero de tweets on ha aparegut. \n",
    "    Aquesta informaci√≥ ha de ser dividida pels diferents partits pol√≠tics. \n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :return : Diccionari amb el format {Partit_Politic : {word : {n_ocur: valor, n_news: valor} } }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Per cada partit hagafem un df on nom√©s tinguem els tweets del partit en q√ºesti√≥\n",
    "    # i cridem a la funci√≥ anterior\n",
    "    return {p : count_words(df.loc[(df['party'] == p)]) for p in get_political_party(df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    words_parties = count_words_parties(df_tweets_train)\n",
    "    print(len(words_parties))\n",
    "    #print(len(words_parties['psc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquests valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'comuns': {\n",
    "        'badalona' : {'n_ocur': 88, 'n_tweets': 76},\n",
    "        'que': {'n_ocur': 123, 'n_tweets': 65}\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "    'psc': {\n",
    "        'badalona' : {'n_ocur': 18, 'n_tweets': 17},\n",
    "        'que': {'n_ocur': 154, 'n_tweets': 66}\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules m√©s freq√ºents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de caracter√≠stiques**\n",
    "\n",
    "L'elecci√≥ de les paraules que formen el vector de caracter√≠stiques √©s un pas cr√≠tic. \n",
    "En funci√≥ de com de bona sigui aquesta descripci√≥, millor funcionar√† el sistema. \n",
    "Tot i que us deixem a vosaltres la pol√≠tica de creaci√≥ del vector de caracter√≠stiques us donem una d'exemple. \n",
    "Per saber quines paraules fer servir una possible estrat√®gia √©s agafar aquelles paraules que apareixen entre un 10 i un 50 per cent del total (sense tenir en compte el partit). \n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNwords(df, words, N, skip=None):\n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un diccionari amb les N paraules m√©s representatives \n",
    "    (les que apareixen amb m√©s freq√º√®ncia) de cadascun dels partits pol√≠tics.\n",
    "    \n",
    "    Tingueu en compte que tamb√© haureu de filtrar aquelles paraules que apareixen en la majoria \n",
    "    de tweets, aix√≠ com les que √∫nicament apareixen en un conjunt molt petit de tweets\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :param words: diccionari amb les paraules i la seva freq√º√®ncia\n",
    "    :param N: nombre de paraules m√©s representatives que volem considerar\n",
    "    :param skip: par√†metre lliure per considerar pol√≠tiques i estrat√®gies per ignorar paraules\n",
    "    :return : Diccionari amb el format {Partit_Pol√≠tic_1: llista_top_words_party_1,  \n",
    "                                        Partit_Pol√≠tic_2: llista_top_words_party_2, ...} \n",
    "    \"\"\"\n",
    "\n",
    "    dic = dict()\n",
    "    n_partits = len(words)\n",
    "    \n",
    "    # Per cada partit,paraules de words_parties\n",
    "    for k,v in words.items():\n",
    "        # Ordenem segons el numero de ocurrencies de les paraules de cada partit\n",
    "        a = sorted(v, key=lambda x: v[x]['n_ocur'], reverse=True)\n",
    "        \n",
    "        if skip: # Si volvem filter per una llista\n",
    "            final = [x for x in a if x not in skip][:N]\n",
    "            dic[k] = final\n",
    "        else:\n",
    "            # Si no volem filtrar per llista hagafem nom√©s aquelles amb un percentatge\n",
    "            # dividint pel nombre de partits\n",
    "            final = [x for x in a if float(words[k][x]['n_ocur']/n_partits)<0.67][:N]\n",
    "            dic[k] = final\n",
    "\n",
    "    return dic\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "B√© per filtrar\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "2/2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erc ['acte', 'sentit', 'aixi', 'lautodeterminacio', 'injusticia', 'paraules', 'pregunta', 'europees', 'dos', 'agressions', '@jordiborras', 'ets', 'garanties', 'encara', 'congreso', 'podem', 'preses', 'senat', 'democrates', 'families'] \n",
      "\n",
      "comuns ['necessita', 'pressupostos', 'socials', 'retallades', 'estas', 'nuestro', 'derecho', 'pogut', 'parlar', 'sha', 'aquestes', 'sera', 'with', 'necesitamos', 'mi', 'dun', 'bon', 'interior', 'aixi', 'som'] \n",
      "\n",
      "cs ['magnifica', 'hacen', 'explica', 'politico', 'sanchez-iglesias', 'socialista', 'merecen', '@cs_andalucia', 'adversarios', 'aun', 'indulto', 'siga', 'avui', 'durante', 'valientes', 'libres', 'deja', 'pedimos', 'otegi', 'lugar'] \n",
      "\n",
      "psc ['derecha', 'todas', 'reforma', 'justicia', 'viure', 'desigualdad', 'construir', 'estat', 'judicial', 'encara', 'parlar', 'restauradors', 've√Ønes', 've√Øns', 'projecte', 'tothom', 'todo', 'sant', 'estamos', '@ballarinmontsek'] \n",
      "\n",
      "ppc ['proces', 'violencia', 'nueva', 'centro', 'haya', 'muchos', 'disfrutando', 'sociales', 'fue', 'cierto', 'publico', 'ningun', 'tot', 'pel', '@daniserranopp', 'esa', 'soy', 'cara', 'pp', 'compa√±eros'] \n",
      "\n",
      "jxcat ['felicitats', '@valtonyc', 'seguir', 'sent', 'lliure', 'tan', 'malgrat', 'santa', 'presidenta', 'estem', 'institucions', 'absolut', 'important', 'mestres', 'bon', 'comunitat', 'justa', 'qual', 'fara', 'podem'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    filter_list = [\"la\",\"de\",\"i\",\"a\",\"que\",\"qu√®\",\"√©s\",\"el\",\"la\",\"les\",\"las\",\"d'\",\n",
    "                   \"l'\",\"n'\",\"un\",\"una\",\"uns\",\"unes\",\"pel\",\"pels\",\"ha\",\"han\",\"ens\",\"en\",\"per\",\"ho\",\"y\",\"tu\",\n",
    "                  \"o\",\"x\",\"t√©\",\"ja\",\"va\",\"vam\",\"has\",\"los\",\"he\",\"tan\",\"hi\",\"es\",\"dels\",\"no\",\"q\",\"els\",\n",
    "                  \"del\",\"amb\",\"d\",\"al\",\"lo\",\"\",\"m√©s\",\"com\",\"fer\",\"hem\",\"als\",\"qui\",\"on\",\"para\",\"con\",\n",
    "                  \"por\",\"sobre\",\"nom√©s\",\"us\",\"aix√≤\",\"se\",\"m√°s\",\"su\",\"aquest\",\"aquests\",\"aquesta\",\"to\",\"esta\",\n",
    "                  \"mi\",\"van\",\"tot\",\"me\",\"nos\",\"molt\",\"este\",\"como\"]\n",
    "    \n",
    "    top_words = topNwords(df_tweets_train, words_parties, 20)\n",
    "    \n",
    "    for k,v in top_words.items():\n",
    "        print(k,v, \"\\n\")\n",
    "    #print(top_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquests valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    'comuns': ['badalona', 'que',...],\n",
    "    ...\n",
    "    'psc': ['partit', 'barcelona',...]\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Caracter√≠stiques\n",
    "Creeu el vector de caracter√≠stiques necessari per a fer l‚Äôentrenament del Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funci√≥ que crea un vector de caracter√≠stiques necessari per a l'entrenament del classificador Naive Bayes\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params top_words: ha de ser el diccionari que retorna topNWords\n",
    "    :return : diccionari o pd.Series que cont√© un np.array per a \n",
    "        cadascuna dels tweets amb el vector de caracter√≠stiques corresponent.\n",
    "    \"\"\"\n",
    "    \n",
    "    tw = []\n",
    "    # Per cada partit, paraules_m√©s_freq√ºents_del_partit\n",
    "    for k,v in top_words.items():\n",
    "        tw += v\n",
    "    tw = set(tw) # Fem un Set - no repetits - ajuntant totes les paraules freq√ºents de tots els partits\n",
    "    \n",
    "    n_words = len(tw)\n",
    "    \n",
    "    dic = dict()\n",
    "    tweets = df['text']\n",
    "    indices = df.index.tolist()\n",
    "    \n",
    "    # Per cada tweet\n",
    "    for i,tweet in enumerate(tweets):\n",
    "        # Creem un vector de caracter√≠stiques amb tot 0's \n",
    "        # del tamany de les nostres paraules freq√ºents\n",
    "        tweet_vector = np.zeros(n_words, dtype=int)\n",
    "        # Fiquem en una llista les paraules normalitzades de cada tweet\n",
    "        norm_tweet = [normalize(word) for word in tweet.split()]\n",
    "        \n",
    "        tweet_tw = []\n",
    "        # Per cada paraula_freq√ºent\n",
    "        for pos,w in enumerate(tw):\n",
    "            # Comprovem si la paraula freq√ºent hi √©s al tweet\n",
    "            if w in norm_tweet:\n",
    "                # Si hi √©s actualitzem el vector de caracter√≠stiques a la posici√≥ X amb un 1\n",
    "                tweet_vector[pos] = 1\n",
    "        \n",
    "        dic[indices[i]] = tweet_vector\n",
    "        \n",
    "    return dic\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Correcte\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "1/1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    N = 20 # Aquest par√†metre el podem canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "    words_parties = count_words_parties(df_tweets_train)\n",
    "    top_words = topNwords(df_tweets_train, words_parties, N)\n",
    "    dict_feat_vector = create_features(df_tweets_train, top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultat ser√† un diccionari tipus (no necess√†riament amb aquests valors):\n",
    "\n",
    "```python\n",
    "{\n",
    "    0: np.array([0, 1, 1, 0, ...]),\n",
    "    1: np.array([0, 1, 1, 1, ...]),\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Na√Øve Bayes\n",
    "\n",
    "Un cop tenim una representaci√≥ necessitem un proc√©s d'aprenentatge que ens permeti passar de la descripci√≥ a una categoria. \n",
    "En aquest lliurament farem servir el classificador Na√Øve Bayes. \n",
    "Aquest classificador forma part de la fam√≠lia de classificadors probabil√≠stics. \n",
    "La sortida d'un classificador probabil√≠stic √©s un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisi√≥ final correspon a la categoria amb m√©s probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabil√≠stics Bayesians es basen en el teorema de Bayes per realitzar els c√†lculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ s√≥n desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisi√≥ se simplifica a:\n",
    "$$ p(y|x) = c ¬∑ p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt s√≥n v√†lides per la majoria de classificadors Bayesians. \n",
    "Na√Øve Bayes es distingeix de la resta perqu√® imposa una condici√≥ encara m√©s restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleat√≤ries. \n",
    "Na√Øve Bayes assumeix que totes elles s√≥n independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equaci√≥ de la seg√ºent forma: La probabilitat qu√® el tweet descrit pel vector de caracter√≠stiques (0,1,0,1,1,1) sigui de la classe \"comuns\" √©s proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"comuns\"  per la probabilitat que la segona paraula s√≠ que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'√∫ltim pas que ens queda √©s trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representaci√≥ de $0$'s i $1$'s indicant que la paraula no apareix (0) o s√≠ apareix (1) al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximaci√≥ freq√ºentista a la probabilitat. \n",
    "Aix√≤ vol dir que calcularem la freq√º√®ncia d'aparici√≥ de cada paraula per a cada categoria. \n",
    "Aquest c√†lcul es fa dividint el nombre de tweets de la categoria que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En general:\n",
    "$$p(x = \\text{\"badalona\"} | y = C)= \\frac{A}{B} $$\n",
    "on A √©s el n√∫mero de tweets de la categoria C on hi apareix la paraula 'badalona' i B √©s el n√∫mero total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts d√®bils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu b√©, la probabilitat pot ser 0 !! \n",
    "Aix√≤ vol dir, que si en el tweet no hi apareix una paraula, no pot ser classificada com un partit pol√≠tic.\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una √∫nica paraula. \n",
    "Per tant, el que s'acostuma a fer √©s donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions √©s fer servir la correcci√≥ de Laplace. \n",
    "Seguint l'exemple anterior la correcci√≥ de Laplace √©s\n",
    "$$p(x= \\text{\"badalona\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M √©s el nombre de categories.\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funci√≥ que hem de calcular en el Naive Bayes √©s un producte. \n",
    "El nombre de caracter√≠stiques del vector √©s el nombre de termes del producte. \n",
    "Aquests nombres s√≥n iguals o menors a 1, si els multipliquem tots entre ells, el resultat ser√† massa petit per a representar-lo en un nombre de punt flotant i el c√†lcul acabar√† sent redu√Øt a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logar√≠tmica i all√† operar fent servir sumes en comptes de multiplicacions.\n",
    "\n",
    "### Classificar:\n",
    "\n",
    "Donat un vector de caracter√≠stiques $x=(x_1,...,x_n)$, per classificar el que farem ser√† calcular la probabilitat de pert√†nyer a cada un dels partits pol√≠tics:\n",
    "\n",
    "$$p(\\text{comuns}|x) = p(\\text{comuns})\\prod_{i=1}^np(x_i|\\text{comuns})$$\n",
    "$$\\cdots$$\n",
    "$$p(\\text{psc}|x) = p(\\text{psc})\\prod_{i=1}^np(x_i|\\text{psc})$$\n",
    "\n",
    "I finalment, el tweet √©s del partit de probabilitat m√†xima. Tingues en compte que per $x_i = 0$ s'ha de considerar la probabilitat inversa, √©s a dir, la probabilitat de ser de la clase $C$ quan $x_i = 0$ ve donada per $1 - p(x_i|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementeu la funci√≥ d'aprenentatge del classificador Na√Øve Bayes (funci√≥ **naive_bayes_learn()**). La funci√≥ ha de mostrar per pantalla el resultat obtingut.\n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilitzades per fer entrenament (aprenentatge). \n",
    "Aquest error √©s un valor molt optimista de com funcionar√† el classificador i mai s'ha de prendre com a mesura per comparar classificadors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funci√≥ que estima les probabilitats marginals condicionades, √©s a dir per cada\n",
    "    partit pol√≠tic C estima $p(x_i|C) = (A + 1) / (B + M)$\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informaci√≥ associada\n",
    "    :params feats: vector de caracter√≠stiques de cada tweet\n",
    "    :return : probabilitats marginals condicionades\n",
    "    \"\"\"\n",
    "    dic = dict()\n",
    "    partits = get_political_party(df)\n",
    "    n_partits = len(partits) # Quantitat de partits = (M)\n",
    "    \n",
    "    # Per cada partit\n",
    "    for p in partits:\n",
    "        # agafar el dataframe nom√©s amb els tweets del partit en concret\n",
    "        df_p = df.loc[(df['party'] == p)]\n",
    "        # Hagafar els indexes corresponents\n",
    "        p_idx = df_p.index.tolist()\n",
    "        \n",
    "        n_tweets_p = len(p_idx)# Longitud de tweets del partit = (B) \n",
    "        \n",
    "        # Creem un vector del tamany del vector de caracter√≠stiques\n",
    "        p_word_times = np.zeros(len(feats[0]), dtype=float)\n",
    "        \n",
    "        # Per cada index del partit\n",
    "        for idx in p_idx:\n",
    "            # Sumem vectors de caracter√≠stiques per treure el numero de tweets on la paraula\n",
    "            # 'X' apareix en cada partit = (A)\n",
    "            p_word_times = np.add(p_word_times, feats[idx])\n",
    "        \n",
    "        # Per cada valor A apliquem la f√≥rmula\n",
    "        for pos,word_times in enumerate(p_word_times):\n",
    "            p_word_times[pos] = (word_times+1)/(n_tweets_p+n_partits)\n",
    "            \n",
    "        dic[p] = p_word_times\n",
    "        \n",
    "    # El diccionari que retornem te l'estructura:\n",
    "    # Partit: [P0, P1, P2, P3, ..., PN]\n",
    "    # De manera que tenim la probabilitat de cada paraula del vector de caracter√≠stiques\n",
    "    # per cada partit\n",
    "    return dic\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "B√©, tot i que aquesta l√≠nia `p_word_times = np.add(p_word_times, feats[idx])` √©s un pel rara, podr√≠eu fer `p_word_times += feats[idx]` i seria el mateix\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "2/2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, split):\n",
    "    \"\"\"\n",
    "    Funci√≥ que separa les dades en aprenentatge i testeig\n",
    "    \n",
    "    :param df:\n",
    "    :param split: proporci√≥ de les dades que seran per l'entrenament\n",
    "    :return : retorna dos dataframes corresponents a l'entrenament i al test\n",
    "    \"\"\"\n",
    "    assert split <= 1, 'Split must be between 0 and 1'\n",
    "    \n",
    "    length = count_tweets(df)\n",
    "    \n",
    "    to_learn = round(split * length)\n",
    "    \n",
    "    # Dividir segons el tamany per agafar nom√©s les files corresponents\n",
    "    df_to_learn = df.loc[:to_learn, :]\n",
    "    df_to_test = df.loc[to_learn+1:, :]\n",
    "    \n",
    "    return (df_to_learn, df_to_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def naive_bayes(df_train, feat_train, feat_test, df_test=None):\n",
    "    \"\"\"\n",
    "    Funci√≥ que implementa el classificador Naive_Bayes, √©s a dir entrena amb les\n",
    "    caracter√≠stiques d'entrenament i despr√©s utilitza les probabilitats estimades\n",
    "    per classificar els vectors de test, segons la f√≥rmula\n",
    "    p(C_j|x) = p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)\n",
    "    i agafant la m√†xima.\n",
    "    \n",
    "    Tingues en compte el problema de l'underflow:\n",
    "    log(p(C_j|x)) = log(p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)) =\n",
    "                  = log(P(C_j)) + log(p(x_1|C_j)) + ... + log(p(x_n|C_j))\n",
    "                  \n",
    "    I recorda, per x_i = 0 cal considerar 1 - p(x_1|C_j).\n",
    "    \n",
    "    Si df_test no √©s None, ha de calcular l'encert sobre les dades de test. √âs a dir,\n",
    "    despr√©s de classificar feat_test ha de comparar la classificaci√≥ amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per a l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracter√≠stiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracter√≠stiques de cada tweet de test\n",
    "    :param df_test: En cas d'estar disponible (per Kaggle no hi √©s), \n",
    "        DataFrame amb els tweets que s'utilitzaran per a test\n",
    "    \n",
    "    :return : Una s√®rie on l'√≠ndex correspon amb els √≠ndexs de df_test i els valors s√≥n la\n",
    "        classificaci√≥ retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    probs_trained = naive_bayes_learn(df_train, feat_train) # Entrenament\n",
    "    partits = get_political_party(df_train) # agafem els partits\n",
    "    \n",
    "    tweets = []\n",
    "    # Per cada vector de caracter√≠stiques del test\n",
    "    for key,value in feat_test.items():\n",
    "        tweet_probs = [] # (p:prob)\n",
    "        for p in partits:\n",
    "            # Per cada partit agafem el vector de probabilitats del partit\n",
    "            probs_partits = probs_trained[p] \n",
    "            current_prob = 0\n",
    "            # Per cada paraula del vector de caracter√≠stiques del test\n",
    "            for pos,w_times in enumerate(value):\n",
    "                # Agafem la probabilitat de l'entrenament de la paraula per al partit X\n",
    "                p_word_train_prob = probs_partits[pos]\n",
    "                if w_times == 0: # Si la paraula en el tweet no surt fem 1 - prob\n",
    "                    p_word_train_prob = 1 - p_word_train_prob\n",
    "                # Fem la suma de logaritmes segons la formula\n",
    "                current_prob += np.log(p_word_train_prob)\n",
    "            # guardem una tupla (partit, probabilitat_de_ser) \n",
    "            tweet_probs.append((p,current_prob))\n",
    "        # Ordenem les probabilitats del tweet del test per agafar la m√°xima\n",
    "        tweet_probs = sorted(tweet_probs, key=lambda x: x[1], reverse=True)\n",
    "        # Guardem el partit que considerem que ha escrit aquest tweet\n",
    "        tweets.append(tweet_probs[0][0])\n",
    "\n",
    "    # Si tenem df_test fem les comprovacions per saber els encerts \n",
    "    # fent la comparaci√≥ amb les nostres suposicions\n",
    "    if not df_test is None:\n",
    "        encerts = 0\n",
    "        c = df_test['party']\n",
    "        for a,v in enumerate(c):\n",
    "            if tweets[a] == v:\n",
    "                encerts += 1\n",
    "        print(\"Encerts: \", encerts, \" of \", len(tweets), \"::\", (encerts/len(tweets))*100, \"% correct\")\n",
    "        \n",
    "    result = pd.Series(data=tweets, index=feat_test.keys())\n",
    "    return result\n",
    "    \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Molt b√©!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "4/4\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encerts:  168  of  383 :: 43.86422976501306 % correct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>jxcat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>psc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>jxcat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>erc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>erc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df_train, df_test = split_train_test(df_tweets_train, 0.8)\n",
    "\n",
    "    N = 50 # Aquest par√†metre el podem canviar i fer proves per avaluar quin √©s el millor valor. \n",
    "    words_topics = count_words_parties(df_train)\n",
    "    top_words = topNwords(df_train, words_topics, N)\n",
    "    \n",
    "    feat_train = create_features(df_train, top_words)\n",
    "    feat_test = create_features(df_test, top_words)\n",
    "        \n",
    "    result = naive_bayes(df_train, feat_train, feat_test, df_test)\n",
    "    \n",
    "    pprint(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "15/15\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle\n",
    "\n",
    "https://www.kaggle.com/t/98e3f4a3150947ebbc634c661bb79560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>psc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    words_topics = count_words_parties(df_tweets_train)\n",
    "    top_words = topNwords(df_tweets_train, words_topics, N)\n",
    "    \n",
    "    feat_train = create_features(df_tweets_train, top_words)\n",
    "    feat_test = create_features(df_tweets_test, top_words)\n",
    "    \n",
    "    result = naive_bayes(df_tweets_train, feat_train, feat_test)\n",
    "    result.index.name = 'tweet_id'\n",
    "    result.name = 'party'\n",
    "    result.to_frame().to_csv('submission.csv')\n",
    "    pprint(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ap√®ndix\n",
    "## Com construir un classificador a partir d'un model de probabiltiats\n",
    "\n",
    "\n",
    "El problema amb la formulaci√≥ √©s que si el nombre de caracter√≠stiques $n$ √©s gran, llavors el c√†lcul de les probabilitats no √©s factible. \n",
    "Per aquest motiu cal reformar el model utilitzant el teorema de Bayes, la probabilitat condicional pot ser descomposta per\n",
    "$$p(C_k|X) = \\frac{p(C_k) \\cdot p(X|C_k)}{p(X)}\n",
    "$$\n",
    "\n",
    "En el nostre cas, el denominador de la fracci√≥ no dep√®n de $C$, i com els valors del vector de caracter√≠stiques $x_{i}$ est√† donat, aquest √©s constant. \n",
    "El numerador √©s equivalent al model de la probabilitat de la junta $p(C_k, x_1, \\cdots, x_n)$ que mitjan√ßant la regla de la cadena pot ser reescrit de la manera seg√ºent:\n",
    "\n",
    "\\begin{aligned}p(C_{k},x_{1},\\dots ,x_{n})&=p(x_{1},\\dots ,x_{n},C_{k})\\\\&=p(x_{1}\\mid x_{2},\\dots ,x_{n},C_{k})p(x_{2},\\dots ,x_{n},C_{k})\\\\&=p(x_{1}\\mid x_{2},\\dots ,x_{n},C_{k})p(x_{2}\\mid x_{3},\\dots ,x_{n},C_{k})p(x_{3},\\dots ,x_{n},C_{k})\\\\&=\\dots \\\\&=p(x_{1}\\mid x_{2},\\dots ,x_{n},C_{k})p(x_{2}\\mid x_{3},\\dots ,x_{n},C_{k})\\dots p(x_{n-1}\\mid x_{n},C_{k})p(x_{n}\\mid -C_{k})p(C_{k})\\\\\\end{aligned}\n",
    "\n",
    "Si recordem que les variables $x_i$ s√≥n independents, obtenim que\n",
    "\n",
    "$$p(x_{i}|x_{i+1},\\dots ,x_{n},C_{k}) = p(x_{i}| C_{k})$$\n",
    "\n",
    "Per tant, el model pot ser expressat:\n",
    "\n",
    "\\begin{aligned}p(C_{k}\\mid x_{1},\\dots ,x_{n})&\\varpropto p(C_{k},x_{1},\\dots ,x_{n})\\\\&=p(C_{k})\\ p(x_{1}\\mid C_{k})\\ p(x_{2}\\mid C_{k})\\ p(x_{3}\\mid C_{k})\\ \\cdots \\\\&=p(C_{k})\\prod _{i=1}^{n}p(x_{i}\\mid C_{k})\\,,\\end{aligned}\n",
    "\n",
    "on $\\varpropto$ denota proporcionalitat.\n",
    "\n",
    "El classificador Naive Bayes combina aquest model amb una regla de decisi√≥. \n",
    "Una regla comuna √©s triar la hip√≤tesi que √©s m√©s probable, aix√≤ es coneix com la regla de decisi√≥ a posteriori m√†xima o MAP. \n",
    "El classificador corresponent, un classificador de Bayes, √©s la funci√≥ que assigna una etiqueta de classe $\\hat{y} = C_{k}$ per alguns $k$ de la seg√ºent manera:\n",
    "\n",
    "$$\\hat{y}={\\underset {k\\in \\{1,\\dots ,K\\}}{\\operatorname {argmax} }}\\ p(C_{k})\\displaystyle \\prod _{i=1}^{n}p(x_{i}\\mid C_{k}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
